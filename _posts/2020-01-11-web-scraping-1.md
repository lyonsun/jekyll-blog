---
layout: post
title: 网络爬虫（一）/ 构建网络爬虫
date: 2020-01-11T08:33:45+02:00
comments: true
categories: [hobby]
tags: [python, coding]
published: false
---

这个部分聚焦于网络爬虫技术的基本原理：怎么使用 Python 向网络服务器请求数据，怎么针对服务器的返回执行基本操作处理，以及怎么通过一种自动化的方式与某个网站开始交互。在最后，你将会很轻松地巡游在整个互联网，构建爬虫以便在不同域之间往来，收集信息，并将这些信息存储起来以为后用。
老实说，网络爬虫技术可以算得上是一个相对来说投入极少但收获却颇多的神奇领域。在相似程度上，你接触到的 90%的网络爬虫项目使用到的技术手段，都能在接下来的六个章节中找到。这个部分涵盖了普通大众在考虑网络爬虫时会试着寻找答案的各个内容：

- 如何从一个域名上抓取 HTML 数据
- 如何解析其中的关键信息
- 如何将解析出来的关键信息保存起来
- 或许还有，如何转移到另一个网页并重复以上操作

这个部分的内容意在为接下来进入第二部分讨论更为复杂的项目奠定坚实的基础。但是千万不要犯傻认为这个第一部分的内容就没有第二部分中那些更高阶的项目那么重要。第一部分中的所有内容将几乎会在编写网络爬虫软件时被长期引用到。

## 第一章：你的第一个网络爬虫

一旦你开始接触到了网络爬虫，你会开始感激网络浏览器给我们提供的很多细微功能。整个网络，如果剥离所有展示层的东西，也就是 HTML 格式处理，CSS 渲染，JavaScript 前端指令执行以及图片展现，会变得让人第一眼看去觉得恐慌。但是在这个以及下一个章节，我们会讨论到如何在没有一个网络浏览器的帮助下格式排版以及解析数据。
这个章节会从以下内容开始讲述：如何就某个网络页面向其网络服务器发送 GET 网络请求的基本知识，如何读取那个网页的 HTML 输出，以及如何进行一些简单的数据剥离以便提取我们寻找的内容。

### 连接

如果你没有花费足够多的时间在了解网络链接或者网络安全方面的知识上的话，互联网的工作原理可能听上去有一点神秘。我们并不想知道每次当我们打开浏览器然后访问 Google 主页面的时候网络具体到底在做些什么，更何况在现在，我们压根就不需要知道。事实上，我会觉得计算机界面发展到现在这个水平以至于大部分使用互联网的人对于它具体怎么工作的并不需要十分了解，这是一件很伟大的事情。
然而，网络爬虫技术需要剥去这些外衣，不仅仅是浏览器层面（比如浏览器怎么通过 HTML，CSS 以及 Javascript 来解析），而且还有偶尔涉及网络链接层面。
为了解释清楚将信息传递到浏览器以便查看所需要的基础设施，我们可以参考以下这个范例。Alice 拥有一个网络服务器。而 Bob 正在使用一台台式机电脑并试图连接到 Alice 的服务器上去。当一个机器想要跟另外一台机器通信的时候，类似下列交换就会发生：

1. Bob 的电脑通过线路的低电压跟高电压来标注，发送一连串的 1 和 0 的字节，这些字节组成某种信息，包含一个信息头文件跟主体。头文件包含 Bob 他自己的本地路由器的 MAC 地址，以及 Alice 的服务器 IP 地址。而主体中会包含 Bob 向 Alice 的服务器应用程序发送的请求。
2. Bob 的本地路由器接受到所有这些 1 和 0 的字节，并将它们组成一个从 Bob 自己的 MAC 地址上发出去的数据包，发到 Alice 的服务器 IP 地址上。Bob 的路由器会将自己的 IP 地址附在数据包上面作为发送地址，并将该数据包发出穿过互联网。
3. Bob 的数据包会在几个中端服务器中穿过，最后导向到正确的地址直至 Alice 的服务器。
4. 最终，Alice 的服务器在自己的 IP 地址上面接收到这个数据包。
5. Alice 的服务器接下来读取数据包上记录的端口地址（对于网络程序来说几乎总是 80 端口。端口可以被看作数据包的公寓楼房间号，而 IP 地址则是该公寓所在的街道地址。数据包上记录的端口地址也可以在头文件中找到，服务器之后会把这个数据包传递给合适的程序，也就是网络服务器程序。
6. 网络服务器程序从服务器处理器上收到一连串数据。这些数据可能是这样说的：

   - 这是一个 GET 请求
   - 下面这个是被请求的文件：index.html

7. 网络服务器接下来就定位到正确的文件，并把这个文件组成一个新的数据包以便发送给 Bob，通过自己的路由器，用同样的方式反向转移给 Bob 的机器。

Voilà！这就是互联网。

那么，网络浏览器在这个交互中到底什么时候开始发挥作用的呢？显然哪里也没有。事实上，浏览器在整个互联网历史中算得上是一个相对新的发明了。Nexus 在 1990 年才发布。
是的，网络浏览器是一个非常有用的程序，用它可以组建信息数据包，向外发送，并解析收到的数据成为图片，声音，视频以及文字。然而，网络浏览器也只是一段代码，而代码是可以被分割成小段，重写，重复使用，甚至用来做任何我们想做的事情。一个网络浏览器可以让处理器发送一些数据给处理无线或者有线节点的程式，但是很多编程语言也有各种库可以用来做相同的事情。
让我们来看看用 Python 是怎么处理的：

```python
from urllib.request import urlopen
html = urlopen("http://pythonscraping.com/pages/page1.html")
print(html.read())
```

你可以将这段代码保存为 scrapetest.py，然后在你的终端使用以下指令来运行：

```bash
$python scrapetest.py
```

注意如果你同时在你的机器上也安装了 Python2.x，那么你可能需要明确使用的是 Python3.x，这时候指令应该如下：

```bash
$python3 scrapetest.py
```
